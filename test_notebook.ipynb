{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test_new = load_from_disk(\"/data2/neeraja/neeraja/data/voxceleb_test_embd_noclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_new = load_from_disk(\"/data2/neeraja/neeraja/data/asapp/slue-phase-2_hvb_train_10fewshots\")\n",
    "# ds_new[0]\n",
    "\n",
    "# ds_new = load_from_disk(\"/data2/neeraja/neeraja/data/asapp/slue-phase-2_hvb_test_audio_lookup\")\n",
    "# ds_new[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 9988/9988 [00:43<00:00, 229.43 examples/s]\n",
      "Generating validation split: 100%|██████████| 1108/1108 [00:01<00:00, 560.26 examples/s]\n",
      "Generating test split: 100%|██████████| 2610/2610 [00:04<00:00, 587.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"zrr1999/MELD_Text_Audio\",cache_dir=\"/data2/neeraja/neeraja/data\",trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Why do all you\\x92re coffee mugs have numbers on the bottom?',\n",
       " 'path': '/data2/neeraja/neeraja/data/downloads/extracted/f0dfebce168f7936b206978a27936c52c698bc9701e2d4b0160c1dc90ec3e287/test/dia0_utt0.flac',\n",
       " 'audio': {'path': '/data2/neeraja/neeraja/data/downloads/extracted/f0dfebce168f7936b206978a27936c52c698bc9701e2d4b0160c1dc90ec3e287/test/dia0_utt0.flac',\n",
       "  'array': array([ 6.79520766e-03,  9.61003701e-03,  8.81721576e-03, ...,\n",
       "         -1.09473864e-05, -5.68230947e-06, -5.42402267e-06]),\n",
       "  'sampling_rate': 16000},\n",
       " 'emotion': 6,\n",
       " 'sentiment': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "        num_rows: 9989\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "        num_rows: 1109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "        num_rows: 2610\n",
      "    })\n",
      "})\n",
      "{'Sr No.': 1, 'Utterance': 'also I was the point person on my company’s transition from the KL-5 to GR-6 system.', 'Speaker': 'Chandler', 'Emotion': 'neutral', 'Sentiment': 'neutral', 'Dialogue_ID': 0, 'Utterance_ID': 0, 'Season': 8, 'Episode': 21, 'StartTime': '00:16:16,059', 'EndTime': '00:16:21,731'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths to the downloaded CSV files\n",
    "base_path = \"/data2/neeraja/neeraja/data/MELD/data/MELD\"\n",
    "train_path = f\"{base_path}/train_sent_emo.csv\"\n",
    "dev_path = f\"{base_path}/dev_sent_emo.csv\"\n",
    "test_path = f\"{base_path}/test_sent_emo.csv\"\n",
    "\n",
    "# Load as pandas DataFrames\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df = pd.read_csv(dev_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Convert to HuggingFace Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Create a DatasetDict\n",
    "meld_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": dev_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Now you can use it like any huggingface dataset\n",
    "print(meld_dataset)\n",
    "print(meld_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 1432,\n",
       " 'id': '20171211-0900-PLENARY-4-en_20171211-17:01:30_3',\n",
       " 'audio': {'path': '20171211-0900-PLENARY-4-en_20171211-17:01:30_3.ogg',\n",
       "  'array': array([ 3.26549285e-03, -2.71464209e-03, -4.50500287e-03, ...,\n",
       "         -1.92926818e-05, -1.30629085e-03,  7.49814790e-04]),\n",
       "  'sampling_rate': 16000},\n",
       " 'speaker_id': '124996',\n",
       " 'normalized_text': 'only his own group and the liberals support the declaration but six groups have refused it.',\n",
       " 'raw_text': 'Only his own Group and the Liberals support the Declaration, but six Groups have refused it.',\n",
       " 'raw_ner': {'type': ['CARDINAL', 'NORP'],\n",
       "  'start': [65, 27],\n",
       "  'length': [3, 8]},\n",
       " 'normalized_ner': {'type': ['CARDINAL', 'NORP'],\n",
       "  'start': [64, 27],\n",
       "  'length': [3, 8]},\n",
       " 'raw_combined_ner': {'type': ['QUANT', 'NORP'],\n",
       "  'start': [65, 27],\n",
       "  'length': [3, 8]},\n",
       " 'normalized_combined_ner': {'type': ['QUANT', 'NORP'],\n",
       "  'start': [64, 27],\n",
       "  'length': [3, 8]},\n",
       " 'local_path': '/home/sshon/.cache/huggingface/datasets/downloads/extracted/b19b518d4dc518d833a5e646a69d8bd32628e42d198310683ffbccb0ca438de0/test/20171211-0900-PLENARY-4-en_20171211-17:01:30_3.ogg'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_p = load_dataset(\"asapp/slue\",'voxpopuli', cache_dir='/data2/neeraja/neeraja/data', split='test')\n",
    "ds_p[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"asapp/slue\",'voxceleb', cache_dir='/data2/neeraja/neeraja/data')\n",
    "data_hvb = load_dataset(\"asapp/slue-phase-2\", 'hvb', cache_dir='/data2/neeraja/neeraja/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'issue_id': '0002f70f7386445b',\n",
       " 'audio': {'path': '0002f70f7386445b_1669_4339.wav',\n",
       "  'array': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  'sampling_rate': 16000},\n",
       " 'speaker_id': '46',\n",
       " 'text': 'hello this is harper valley national bank',\n",
       " 'utt_index': 1,\n",
       " 'channel': 2,\n",
       " 'role': 'agent',\n",
       " 'start_ms': 1669,\n",
       " 'duration_ms': 2670,\n",
       " 'intent': 'replace card',\n",
       " 'dialog_acts': ['statement_open']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hvb['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"asapp/slue\",'voxceleb', cache_dir='/data2/neeraja/neeraja/data', split='train')\n",
    "ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 5777\n",
      "\n",
      "First 5 train indices: ['2782', '3238', '2702', '4060', '5600']\n",
      "\n",
      "Total few-shot examples: 115540\n",
      "Number of missing indices: 0\n",
      "First 10 missing indices: []\n",
      "\n",
      "Min train index: 0\n",
      "Max train index: 5776\n",
      "Min missing index: N/A\n",
      "Max missing index: N/A\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "from datasets import load_from_disk\n",
    "import logging\n",
    "\n",
    "# Load training dataset\n",
    "ds_train = load_from_disk(\"/data2/neeraja/neeraja/data/asapp/slue_voxceleb_train_20fewshots\")\n",
    "# ds_test = load_from_disk(\"/data2/neeraja/neeraja/data/voxceleb_test_embd_noclass\")\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(ds_train)}\")\n",
    "# print(f\"Test dataset size: {len(ds_test)}\")\n",
    "\n",
    "# Check indices in train dataset\n",
    "train_indices = set(str(item['index']) for item in ds_train)\n",
    "print(f\"\\nFirst 5 train indices: {list(train_indices)[:5]}\")\n",
    "\n",
    "# Check few-shot examples in test dataset\n",
    "missing_indices = []\n",
    "total_fewshot = 0\n",
    "\n",
    "for item in ds_train:\n",
    "    if 'few_shot_examples' in item:\n",
    "        for example in item['few_shot_examples']:\n",
    "            total_fewshot += 1\n",
    "            if str(example['index']) not in train_indices:\n",
    "                missing_indices.append(example['index'])\n",
    "\n",
    "print(f\"\\nTotal few-shot examples: {total_fewshot}\")\n",
    "print(f\"Number of missing indices: {len(missing_indices)}\")\n",
    "print(f\"First 10 missing indices: {missing_indices[:10]}\")\n",
    "\n",
    "# Print index statistics\n",
    "print(f\"\\nMin train index: {min(int(idx) for idx in train_indices)}\")\n",
    "print(f\"Max train index: {max(int(idx) for idx in train_indices)}\")\n",
    "print(f\"Min missing index: {min(missing_indices) if missing_indices else 'N/A'}\")\n",
    "print(f\"Max missing index: {max(missing_indices) if missing_indices else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 2308,\n",
       " 'id': 'id10295_3tvnlmkCiTw_00013',\n",
       " 'audio': {'path': 'id10295_3tvnlmkCiTw_00013.flac',\n",
       "  'array': array([-0.00033569,  0.00436401,  0.00610352, ..., -0.00494385,\n",
       "         -0.00616455, -0.00637817]),\n",
       "  'sampling_rate': 16000},\n",
       " 'speaker_id': 'id10295',\n",
       " 'normalized_text': 'i had a fan uh while i was at the indianapolis five hundred with dempsey um',\n",
       " 'sentiment': 'Neutral',\n",
       " 'start_second': 0.0,\n",
       " 'end_second': 6.08,\n",
       " 'local_path': '/home/sshon/.cache/huggingface/datasets/downloads/extracted/65ae398663417878d45d4495e2d6a7982cc537ea2bd968df8f018ab6e5d02215/test_raw/id10295_3tvnlmkCiTw_00013.flac'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"asapp/slue\",'voxceleb', cache_dir='/data2/neeraja/neeraja/data')\n",
    "ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dialog acts:\n",
      "- acknowledge\n",
      "- answer_agree\n",
      "- answer_dis\n",
      "- answer_general\n",
      "- apology\n",
      "- backchannel\n",
      "- disfluency\n",
      "- other\n",
      "- question_check\n",
      "- question_general\n",
      "- question_repeat\n",
      "- self\n",
      "- statement_close\n",
      "- statement_general\n",
      "- statement_instruct\n",
      "- statement_open\n",
      "- statement_problem\n",
      "- thanks\n",
      "\n",
      "Total number of unique dialog acts: 18\n"
     ]
    }
   ],
   "source": [
    "# Get all unique dialog acts\n",
    "unique_dialog_acts = set()\n",
    "for item in data_hvb['train']:\n",
    "    unique_dialog_acts.update(item['dialog_acts'])\n",
    "\n",
    "# Convert to sorted list for better readability\n",
    "unique_dialog_acts = sorted(list(unique_dialog_acts))\n",
    "\n",
    "# Print the results\n",
    "print(\"Unique dialog acts:\")\n",
    "for act in unique_dialog_acts:\n",
    "    print(f\"- {act}\")\n",
    "\n",
    "# Print total count\n",
    "print(f\"\\nTotal number of unique dialog acts: {len(unique_dialog_acts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
